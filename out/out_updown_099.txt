
Namespace(data_view='updown', dims=256, ext='_tmp5_0.99', model='ResNetUNet', num_classes=1, prun_config_file='config_ResNetUNet_0.99', sparsity_type='irregular', test_batch_size=1)
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 64, 256, 256]           1,792
              ReLU-2         [-1, 64, 256, 256]               0
            Conv2d-3         [-1, 64, 256, 256]          36,928
              ReLU-4         [-1, 64, 256, 256]               0
            Conv2d-5         [-1, 64, 128, 128]           9,408
            Conv2d-6         [-1, 64, 128, 128]           9,408
       BatchNorm2d-7         [-1, 64, 128, 128]             128
       BatchNorm2d-8         [-1, 64, 128, 128]             128
              ReLU-9         [-1, 64, 128, 128]               0
             ReLU-10         [-1, 64, 128, 128]               0
        MaxPool2d-11           [-1, 64, 64, 64]               0
        MaxPool2d-12           [-1, 64, 64, 64]               0
           Conv2d-13           [-1, 64, 64, 64]          36,864
           Conv2d-14           [-1, 64, 64, 64]          36,864
      BatchNorm2d-15           [-1, 64, 64, 64]             128
      BatchNorm2d-16           [-1, 64, 64, 64]             128
             ReLU-17           [-1, 64, 64, 64]               0
             ReLU-18           [-1, 64, 64, 64]               0
           Conv2d-19           [-1, 64, 64, 64]          36,864
           Conv2d-20           [-1, 64, 64, 64]          36,864
      BatchNorm2d-21           [-1, 64, 64, 64]             128
      BatchNorm2d-22           [-1, 64, 64, 64]             128
             ReLU-23           [-1, 64, 64, 64]               0
             ReLU-24           [-1, 64, 64, 64]               0
       BasicBlock-25           [-1, 64, 64, 64]               0
       BasicBlock-26           [-1, 64, 64, 64]               0
           Conv2d-27           [-1, 64, 64, 64]          36,864
           Conv2d-28           [-1, 64, 64, 64]          36,864
      BatchNorm2d-29           [-1, 64, 64, 64]             128
      BatchNorm2d-30           [-1, 64, 64, 64]             128
             ReLU-31           [-1, 64, 64, 64]               0
             ReLU-32           [-1, 64, 64, 64]               0
           Conv2d-33           [-1, 64, 64, 64]          36,864
           Conv2d-34           [-1, 64, 64, 64]          36,864
      BatchNorm2d-35           [-1, 64, 64, 64]             128
      BatchNorm2d-36           [-1, 64, 64, 64]             128
             ReLU-37           [-1, 64, 64, 64]               0
             ReLU-38           [-1, 64, 64, 64]               0
       BasicBlock-39           [-1, 64, 64, 64]               0
       BasicBlock-40           [-1, 64, 64, 64]               0
           Conv2d-41          [-1, 128, 32, 32]          73,728
           Conv2d-42          [-1, 128, 32, 32]          73,728
      BatchNorm2d-43          [-1, 128, 32, 32]             256
      BatchNorm2d-44          [-1, 128, 32, 32]             256
             ReLU-45          [-1, 128, 32, 32]               0
             ReLU-46          [-1, 128, 32, 32]               0
           Conv2d-47          [-1, 128, 32, 32]         147,456
           Conv2d-48          [-1, 128, 32, 32]         147,456
      BatchNorm2d-49          [-1, 128, 32, 32]             256
      BatchNorm2d-50          [-1, 128, 32, 32]             256
           Conv2d-51          [-1, 128, 32, 32]           8,192
           Conv2d-52          [-1, 128, 32, 32]           8,192
      BatchNorm2d-53          [-1, 128, 32, 32]             256
      BatchNorm2d-54          [-1, 128, 32, 32]             256
             ReLU-55          [-1, 128, 32, 32]               0
             ReLU-56          [-1, 128, 32, 32]               0
       BasicBlock-57          [-1, 128, 32, 32]               0
       BasicBlock-58          [-1, 128, 32, 32]               0
           Conv2d-59          [-1, 128, 32, 32]         147,456
           Conv2d-60          [-1, 128, 32, 32]         147,456
      BatchNorm2d-61          [-1, 128, 32, 32]             256
      BatchNorm2d-62          [-1, 128, 32, 32]             256
             ReLU-63          [-1, 128, 32, 32]               0
             ReLU-64          [-1, 128, 32, 32]               0
           Conv2d-65          [-1, 128, 32, 32]         147,456
           Conv2d-66          [-1, 128, 32, 32]         147,456
      BatchNorm2d-67          [-1, 128, 32, 32]             256
      BatchNorm2d-68          [-1, 128, 32, 32]             256
             ReLU-69          [-1, 128, 32, 32]               0
             ReLU-70          [-1, 128, 32, 32]               0
       BasicBlock-71          [-1, 128, 32, 32]               0
       BasicBlock-72          [-1, 128, 32, 32]               0
           Conv2d-73          [-1, 256, 16, 16]         294,912
           Conv2d-74          [-1, 256, 16, 16]         294,912
      BatchNorm2d-75          [-1, 256, 16, 16]             512
      BatchNorm2d-76          [-1, 256, 16, 16]             512
             ReLU-77          [-1, 256, 16, 16]               0
             ReLU-78          [-1, 256, 16, 16]               0
           Conv2d-79          [-1, 256, 16, 16]         589,824
           Conv2d-80          [-1, 256, 16, 16]         589,824
      BatchNorm2d-81          [-1, 256, 16, 16]             512
      BatchNorm2d-82          [-1, 256, 16, 16]             512
           Conv2d-83          [-1, 256, 16, 16]          32,768
           Conv2d-84          [-1, 256, 16, 16]          32,768
      BatchNorm2d-85          [-1, 256, 16, 16]             512
      BatchNorm2d-86          [-1, 256, 16, 16]             512
             ReLU-87          [-1, 256, 16, 16]               0
             ReLU-88          [-1, 256, 16, 16]               0
       BasicBlock-89          [-1, 256, 16, 16]               0
       BasicBlock-90          [-1, 256, 16, 16]               0
           Conv2d-91          [-1, 256, 16, 16]         589,824
           Conv2d-92          [-1, 256, 16, 16]         589,824
      BatchNorm2d-93          [-1, 256, 16, 16]             512
      BatchNorm2d-94          [-1, 256, 16, 16]             512
             ReLU-95          [-1, 256, 16, 16]               0
             ReLU-96          [-1, 256, 16, 16]               0
           Conv2d-97          [-1, 256, 16, 16]         589,824
           Conv2d-98          [-1, 256, 16, 16]         589,824
      BatchNorm2d-99          [-1, 256, 16, 16]             512
     BatchNorm2d-100          [-1, 256, 16, 16]             512
            ReLU-101          [-1, 256, 16, 16]               0
            ReLU-102          [-1, 256, 16, 16]               0
      BasicBlock-103          [-1, 256, 16, 16]               0
      BasicBlock-104          [-1, 256, 16, 16]               0
          Conv2d-105            [-1, 512, 8, 8]       1,179,648
          Conv2d-106            [-1, 512, 8, 8]       1,179,648
     BatchNorm2d-107            [-1, 512, 8, 8]           1,024
     BatchNorm2d-108            [-1, 512, 8, 8]           1,024
            ReLU-109            [-1, 512, 8, 8]               0
            ReLU-110            [-1, 512, 8, 8]               0
          Conv2d-111            [-1, 512, 8, 8]       2,359,296
          Conv2d-112            [-1, 512, 8, 8]       2,359,296
     BatchNorm2d-113            [-1, 512, 8, 8]           1,024
     BatchNorm2d-114            [-1, 512, 8, 8]           1,024
          Conv2d-115            [-1, 512, 8, 8]         131,072
          Conv2d-116            [-1, 512, 8, 8]         131,072
     BatchNorm2d-117            [-1, 512, 8, 8]           1,024
     BatchNorm2d-118            [-1, 512, 8, 8]           1,024
            ReLU-119            [-1, 512, 8, 8]               0
            ReLU-120            [-1, 512, 8, 8]               0
      BasicBlock-121            [-1, 512, 8, 8]               0
      BasicBlock-122            [-1, 512, 8, 8]               0
          Conv2d-123            [-1, 512, 8, 8]       2,359,296
          Conv2d-124            [-1, 512, 8, 8]       2,359,296
     BatchNorm2d-125            [-1, 512, 8, 8]           1,024
     BatchNorm2d-126            [-1, 512, 8, 8]           1,024
            ReLU-127            [-1, 512, 8, 8]               0
            ReLU-128            [-1, 512, 8, 8]               0
          Conv2d-129            [-1, 512, 8, 8]       2,359,296
          Conv2d-130            [-1, 512, 8, 8]       2,359,296
     BatchNorm2d-131            [-1, 512, 8, 8]           1,024
     BatchNorm2d-132            [-1, 512, 8, 8]           1,024
            ReLU-133            [-1, 512, 8, 8]               0
            ReLU-134            [-1, 512, 8, 8]               0
      BasicBlock-135            [-1, 512, 8, 8]               0
      BasicBlock-136            [-1, 512, 8, 8]               0
          Conv2d-137            [-1, 512, 8, 8]         262,656
            ReLU-138            [-1, 512, 8, 8]               0
        Upsample-139          [-1, 512, 16, 16]               0
          Conv2d-140          [-1, 256, 16, 16]          65,792
            ReLU-141          [-1, 256, 16, 16]               0
          Conv2d-142          [-1, 512, 16, 16]       3,539,456
            ReLU-143          [-1, 512, 16, 16]               0
        Upsample-144          [-1, 512, 32, 32]               0
          Conv2d-145          [-1, 128, 32, 32]          16,512
            ReLU-146          [-1, 128, 32, 32]               0
          Conv2d-147          [-1, 256, 32, 32]       1,474,816
            ReLU-148          [-1, 256, 32, 32]               0
        Upsample-149          [-1, 256, 64, 64]               0
          Conv2d-150           [-1, 64, 64, 64]           4,160
            ReLU-151           [-1, 64, 64, 64]               0
          Conv2d-152          [-1, 256, 64, 64]         737,536
            ReLU-153          [-1, 256, 64, 64]               0
        Upsample-154        [-1, 256, 128, 128]               0
          Conv2d-155         [-1, 64, 128, 128]           4,160
            ReLU-156         [-1, 64, 128, 128]               0
          Conv2d-157        [-1, 128, 128, 128]         368,768
            ReLU-158        [-1, 128, 128, 128]               0
        Upsample-159        [-1, 128, 256, 256]               0
          Conv2d-160         [-1, 64, 256, 256]         110,656
            ReLU-161         [-1, 64, 256, 256]               0
          Conv2d-162          [-1, 1, 256, 256]              65
================================================================
Total params: 28,976,321
Trainable params: 28,976,321
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.75
Forward/backward pass size (MB): 543.00
Params size (MB): 110.54
Estimated Total Size (MB): 654.29
----------------------------------------------------------------
+-----------------------------------------+------------+
|                 Modules                 | Parameters |
+-----------------------------------------+------------+
|         base_model.conv1.weight         |    9408    |
|          base_model.bn1.weight          |     64     |
|           base_model.bn1.bias           |     64     |
|     base_model.layer1.0.conv1.weight    |   36864    |
|      base_model.layer1.0.bn1.weight     |     64     |
|       base_model.layer1.0.bn1.bias      |     64     |
|     base_model.layer1.0.conv2.weight    |   36864    |
|      base_model.layer1.0.bn2.weight     |     64     |
|       base_model.layer1.0.bn2.bias      |     64     |
|     base_model.layer1.1.conv1.weight    |   36864    |
|      base_model.layer1.1.bn1.weight     |     64     |
|       base_model.layer1.1.bn1.bias      |     64     |
|     base_model.layer1.1.conv2.weight    |   36864    |
|      base_model.layer1.1.bn2.weight     |     64     |
|       base_model.layer1.1.bn2.bias      |     64     |
|     base_model.layer2.0.conv1.weight    |   73728    |
|      base_model.layer2.0.bn1.weight     |    128     |
|       base_model.layer2.0.bn1.bias      |    128     |
|     base_model.layer2.0.conv2.weight    |   147456   |
|      base_model.layer2.0.bn2.weight     |    128     |
|       base_model.layer2.0.bn2.bias      |    128     |
| base_model.layer2.0.downsample.0.weight |    8192    |
| base_model.layer2.0.downsample.1.weight |    128     |
|  base_model.layer2.0.downsample.1.bias  |    128     |
|     base_model.layer2.1.conv1.weight    |   147456   |
|      base_model.layer2.1.bn1.weight     |    128     |
|       base_model.layer2.1.bn1.bias      |    128     |
|     base_model.layer2.1.conv2.weight    |   147456   |
|      base_model.layer2.1.bn2.weight     |    128     |
|       base_model.layer2.1.bn2.bias      |    128     |
|     base_model.layer3.0.conv1.weight    |   294912   |
|      base_model.layer3.0.bn1.weight     |    256     |
|       base_model.layer3.0.bn1.bias      |    256     |
|     base_model.layer3.0.conv2.weight    |   589824   |
|      base_model.layer3.0.bn2.weight     |    256     |
|       base_model.layer3.0.bn2.bias      |    256     |
| base_model.layer3.0.downsample.0.weight |   32768    |
| base_model.layer3.0.downsample.1.weight |    256     |
|  base_model.layer3.0.downsample.1.bias  |    256     |
|     base_model.layer3.1.conv1.weight    |   589824   |
|      base_model.layer3.1.bn1.weight     |    256     |
|       base_model.layer3.1.bn1.bias      |    256     |
|     base_model.layer3.1.conv2.weight    |   589824   |
|      base_model.layer3.1.bn2.weight     |    256     |
|       base_model.layer3.1.bn2.bias      |    256     |
|     base_model.layer4.0.conv1.weight    |  1179648   |
|      base_model.layer4.0.bn1.weight     |    512     |
|       base_model.layer4.0.bn1.bias      |    512     |
|     base_model.layer4.0.conv2.weight    |  2359296   |
|      base_model.layer4.0.bn2.weight     |    512     |
|       base_model.layer4.0.bn2.bias      |    512     |
| base_model.layer4.0.downsample.0.weight |   131072   |
| base_model.layer4.0.downsample.1.weight |    512     |
|  base_model.layer4.0.downsample.1.bias  |    512     |
|     base_model.layer4.1.conv1.weight    |  2359296   |
|      base_model.layer4.1.bn1.weight     |    512     |
|       base_model.layer4.1.bn1.bias      |    512     |
|     base_model.layer4.1.conv2.weight    |  2359296   |
|      base_model.layer4.1.bn2.weight     |    512     |
|       base_model.layer4.1.bn2.bias      |    512     |
|           base_model.fc.weight          |   512000   |
|            base_model.fc.bias           |    1000    |
|           layer0_1x1.0.weight           |    4096    |
|            layer0_1x1.0.bias            |     64     |
|           layer1_1x1.0.weight           |    4096    |
|            layer1_1x1.0.bias            |     64     |
|           layer2_1x1.0.weight           |   16384    |
|            layer2_1x1.0.bias            |    128     |
|           layer3_1x1.0.weight           |   65536    |
|            layer3_1x1.0.bias            |    256     |
|           layer4_1x1.0.weight           |   262144   |
|            layer4_1x1.0.bias            |    512     |
|            conv_up3.0.weight            |  3538944   |
|             conv_up3.0.bias             |    512     |
|            conv_up2.0.weight            |  1474560   |
|             conv_up2.0.bias             |    256     |
|            conv_up1.0.weight            |   737280   |
|             conv_up1.0.bias             |    256     |
|            conv_up0.0.weight            |   368640   |
|             conv_up0.0.bias             |    128     |
|       conv_original_size0.0.weight      |    1728    |
|        conv_original_size0.0.bias       |     64     |
|       conv_original_size1.0.weight      |   36864    |
|        conv_original_size1.0.bias       |     64     |
|       conv_original_size2.0.weight      |   110592   |
|        conv_original_size2.0.bias       |     64     |
|             conv_last.weight            |     64     |
|              conv_last.bias             |     1      |
+-----------------------------------------+------------+
Total Trainable Params: 18312809
================= Total 313 imgs process: 5687.323570 ms
+++++++++++++++++++++++++++++
Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!
Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!
Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!
Warning: variables __flops__ or __params__ are already defined for the moduleMaxPool2d ptflops can affect your code!
Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!
Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!
Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!
Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!
Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!
Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!
Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!
Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!
Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!
Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!
Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!
Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!
Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!
Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!
Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!
Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!
Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!
Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!
Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!
Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!
Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!
Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!
Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!
Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!
Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!
Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!
Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!
Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!
Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!
Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!
Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!
Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!
Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!
Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!
Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!
Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!
Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!
Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!
Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!
Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!
Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!
Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!
Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!
Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!
Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!
Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!
Computational complexity:       20.0 GMac
Number of parameters:           18.31 M 
+++++++++++++++++++++++++++++

